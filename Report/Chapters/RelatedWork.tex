\chapter{Related Work}
\label{cha:related-work}

\section{heterogeneous processors}
\todo{Note: Most likely, most of this content is too much, and probably too detailed. But I fill in too much at first, and cut down afterwards (don't have to reread the papers that way)}

Kumar \textit{et al} \cite{heterogeneous-ee, heterogeneous-perf, heterogeneous-arch} explores the diverse possibilities offered by heterogeneous architectures. 
They prediction that core diversity will be of higher value than uniformity, and will offer much greater ability to adapt to the demands of the applications.
They argue that the objective function can change over time, such as power conditions, application switches, or changes of demands within the application\cite{heterogeneous-ee}. 

\subsection{Energy Efficiency}
In one experiment, Kumar \textit{et al}\cite{heterogeneous-ee} ran a simulation where they combined four generations from the Alpha family: EV4 (Alpha 21064), EV5 (Alpha 21164), EV6 (Alpha 21264) and a single-threaded version of EV8 (Alpha 21464).
Only one application would run at the time, on one core, while the others were powered down.
The architecture, with the said cores and their relative sizes to one another can be seen in \todo{Figure needs resizing}
\cite{fig:Kumar1}.

\begin{figure}[htb]
    \centering
    \includegraphics[width=1.0\textwidth]{Figures/Heterogeneous/Kumar1}
    \caption{Cores used in \cite{heterogeneous-ee}, and their relative sizes.}
    \label{fig:Kumar1}
\end{figure}


14 benchmarks from SPEC2000 were used in this experiment, simulated using SMTSIM, and both energy and energy-delay were measured.

For this experiment, it was assumed that the system knew the needs of every application, and selected core statically. 
Results showed average energy savings of 32\%, and average performance loss at only 2.6\%, relative to the EV8 core.
Kumar \cite{et al} also used this experiment to show that dynamic core switching outperforms the best static core selection.
Simple heuristics would sample the cores at regular intervals, and execute core switch based on the results.
The heuristics achieved up to 93\% of the energy-delay gains compared to the best static selection. 

\subsection{Performance}
In another experiment, Kumar \textit{et al}\cite{heterogeneous-perf} showed that heterogeneity can be exploited to gain increased performance, for multithreaded workload.
They point out that heterogeneous architectures are advantagous for two reasons.

Firstly, they offer efficient adaptation to application diversity, as applications differs in their resource needs.
Some are compute intensitive and make good use of an out-of-order pipeline with high issue-width, while others may be memory-bound, and will underutulize advanced cores.
They may perform almost as well on an in-order core with low issue-width\cite{heterogeneous-perf}.

Secondly, heterogeneous architectures offers more efficiently use of the die area for a given thread-level parallelism.
A complex core can be replace by multiple smaller simpler cores. 
Since the process or thread level paralellism varies within most systems, a mix of cores that offers some large cores for hish single-thread performce, and some small cores with high throughput per die area, is a potentially attractive area. \cite{heterogeneous-perf}

In contrast to the previous paper by Kumar \textit{et al}\cite{heterogeneous-ee}, this experiment assigned multiple threads for multiple cores, and best global assignment was considered above best assignment for a selected application.
EV5 and EV6 were chosen for this project, with one EV6 nearly equal to five EV5 in size.
With the total area anvailable for the architecture assumed to be 100 \todo{fix exponent}mm\^2, the space could have maximum 4 EV6 cores, or 20 EV5 cores
Three EV6 cores and five EV5 were chosen for this experiment, with expectation that it would perform well over a wide range of available thread-level parallelism. 
A small number from SPEC2000 benchmakrs were chosen, with the focus on evaluating varying number of threads.
SMTSIM and Simpoint were used for the simulation.
\todo{Mind-blowing, consider removal}Evaluation metric was weighted speedup, which in this context is the arithmetic sum of the individual IPCs of the threads constituting a workload divided by their IPC on a baseline configuration when running alone.
In addition to performance gain, application response time within varying queue lengths are tested as well,  to give insight on how well heterogeneous processors handles large queues, compared to best homogeneous systems.

Best static scheduling ensures that threads that are least affected by the difference between the EV5 and the EV6 are assigned to the EV5 processors, when all EV6 processors are busy.
When the number of threads passes 4, the weighted speedup increases on the heterogeneous system, compared to a homogeneous CMP with 4 EV6.
When the number of threads passes 13, a CMP with 20 EV5 performs better, though this can be changed with a different combination of EV5 and EV6 cores.
This can be seen in \todo{Didn't show result figure from previous paper, consider if this leads to inconsistency.}figure \cite{fig:Kumar2}.
\todo{Following 2 sentences are nearly ripoff from \cite{heterogeneous-perf, consider making quote or what?}}Compared to 4 EV6 cores, the heterogeneous processor performed up to 37\% better with an average 26\% improvement over the configuration considering 1-20 threads. 
Compared to 20 EV5 cores, the performance was up to 2.3 times better, and averaged 23\% better over that same range. \cite{heterogeneous-perf}
Using dynamic heuristics for core assignment further increased the performance.

\begin{figure}[htb]
    \centering
    \includegraphics[width=1.0\textwidth]{Figures/Heterogeneous/Kumar2}
    \caption{Benefits from heterogeneity - static scheduling for inter-thread diversity, as seen in \cite{heterogeneous-perf}.}
    \label{fig:Kumar2}
\end{figure}

For testing response time in an open system, and how various que length affects it, jobs with an average distrubition of 200 million cycles were generated were created randomly and executed.
Then different mean job arrival rates with exponential distribution were simulated.
Testing revealed a great difference between saturation for a homogenous system with 4 EV6, and the heterogeneous processor.
For the former, the unbounded response time is seen as the arrival rate approaches its maximum throughput around 2 jobs per 100 million cycles.
From there, the run queue became infinate.
The heterogeneous system remained stable well beyond that point.
The degredation was also more graceful under heavier loads than for homogeneous processors.
This can be seen in figure \cite{Kumar3}.

\begin{figure}[htb]
    \centering
    \includegraphics[width=1.0\textwidth]{Figures/Heterogeneous/Kumar3}
    \caption{Limiting response-time for various loads, as seen in \cite{heterogeneous-perf}.}
    \label{fig:Kumar3}
\end{figure}

\subsection{Optimal architecture}
In a third experiment, Kumar \textit{et al}\cite{heterogeneous-arch} has taken a closer look at what is good heterogeneous design.
They argue that while the previous experiments gave increased energy efficiency and performace, a heterogeneous system should be designed from scratch, instead of using pre-existing core designs.
While they surpassed homogeneous designs, pre-existing cores failed to reach the full potential of heterogeneousy for three reasons: They present low flexibility in choices, the core choices remain monotonic, and third, best heterogeneous design are composed of specialized core architectures\cite{heterogeneous-arch}.
But also, if pre-existing cores are not used, additional costs in design, verification and testing must be evaluated, to see if the benefits is worth the cost.

Kumar \textit{et al} made three significant contributions in this experiment. 
First, benefits of heterogeneity in power and area efficient architectures is re-evaluated, with new benefits and higher gains shown.
Secondly, methodologies for for arriving at good heterogeneous designs are demonstrated.
Thirdly, a number of key principles critical to effective design of future chip multiprocessors are identified.

Several conclusions were derived:
\todo{Itemize or cut down at this point}The most efficient heterogeneous multiprocessors were not constructed from cores that make good general-purpose uniprocessor cores, or cores that would appear in a good homogeneous multicure architecture.
Each core was individually tuned for a class of applications with common characteristics.
The results are usually non-monotonic processors.
And performance advantages of heterogeneous multiprocessors, including non-monotonic also holds for completely homogeneous workloads.
In those cases, the diversity across different workloads are exploited.

\todo{Just a headnote. Remove when agreed or fixed}\textbf{Simplification assumptions dropped}

%A number of 480 unique cores could be made from the various parameters set for this experiment.
%\todo{Makes absolutely sense at all. Cut down or delete, but some way explain what the parameters were.}These were the issue width, I-cache size, D-cache size, L2 Cache size, Memory Channel, number of FP-IntMul-ALU units, IntQ-fpQ and IntFp PhysReg-ROB (OOO), ITLB-DTLB and LD/St Queue.
%\todo{Mention the "best fit" problem from monotonic cores?}
%\textbf{Insert mentioned todo-content or remove. And find suitable place}

A fixed number of four cores was used for this experiment.
In addition to testing the various core builds, the combinations were tested against varying area and power constraints, with their performance compared to the best homogeneous processors.
Static mapping were mainly used for this experiment, but few tests with dynamic mapping showed further increase in performance, since a thread could be moved around to most suitable core at any phase of its execution. 

%\todo{Strongly considering deleting (commenting out) the following paragraph. Too much unnecessary details.}The workloads come from seven benchmarks from the SPEC suite, classified int o processor bound or bandwidth bound.
%The chosen benchmarks are carefully selected, and represents the entire SPEC suite.
%In additional, three other benchmarks from other suites are chosen as well.
%Every multiprocessor is evaluated on two classes of workloads, called \textit{all different} and \textit{all same}.
%\todo{Warning: Direct rip-off. Consider "quote"-form}The former consist of all possible 4-threaded combinations that can be constructed such that each of the 4 threads running at a different time.
%The latter consists of all combinations that can be constructed so that all the 4 threads running at a time are the same.

%\todo{Direct copy, rewrite the paragraph}We use weighted speedup [21] for our evaluations. In this paper, weighted speedup measures the arithmetic sum of each running thread’s IPC, divided by its IPC on the simplest core considered in this study when running alone. The IPC is derived by running a thread for a fixed amount of time. We believe that this metric guards against multiprocessor design points that produce artificial speedups by simply favoring high-IPC threads.%For completeness reasons, we also performed all our evaluations for total IPC as well and found that while the absolute results were different, there was no significant difference in trends or analysis.

It turned out that the more constricted the anvailable power or area, the more gain it was with custom heterogeniety, as homogeneous multiprocessors could only perform any task at maximum if the power budget was generous.
But as designs become more aggressive, one will want to place more cores on the die, and power budgets per core will likely tighten more severly.
Heterogeneous designs dampen the effects of constrained power budgets \cite{heterogeneous-arch}.

Any best heterogeneous design for the different tested power and area constraint were very different from best homogeneous design, underlining the need to design heterogeneous processors from a clean slate, rather than modifying an existing core design.
Monotonous designs (for instance, different generations of cores from same family) does not exploit heterogeneity equally well.
For instance, the benchmark \textit{mcf} from \cite{heterogeneous-ee} were mapped on EV6 or single-threaded EV8-, in spite of having low ILP.
The reason was the larger caches of these cores, causing the advances capabilities of these larger cores to be underutulized.
Summed up: Heterogeneous multicore processors designed from clean slate gives better performance.
\todo{In lack of better word to finish off this mind-boggling work...}Blegh!...

\subsection{Uncore}
Gupta \textit{et al}\cite{heterogeneous-uncore} ran experiments with a heterogeneous multiprocessor, with the goal of measuring the impact of "uncore" power on the energy efficiency of heterogeneous multicore processors.
In this experiment, they focused on the use of client devices, where energy is a premium resource and the workload profiles are diverse.
The uncore is a collection of components of a processor, not in the core, but essential for core performance.
Some of these components are the last level cache (LLC), integrated memory controllers (IMC), on-chip interconnect (OCI), power control logic (PWR), etc.
With growing cache size and integration of various SoC components on the CPU die, the uncore is becoming an increasingly imporant contributor \cite{heterogeneous-uncore}.

If a core has varying levels of sleep states, where the "deeper the sleep", the less power used, then uncore will be as active as the most active core.
If three cores are idle (or on low activity, and one core is on highest activity, then the uncore will be on the highest activity.
If for a task, the choice is between a big fast core, or a more power efficient small core, and the small core is chosen, the ucore will stay active for longer time, impacting the possible energy saving.
This can be seen illustrated in figure \cite{fig:Uncore1}.

\begin{figure}[htb]
    \centering
    \includegraphics[width=1.0\textwidth]{Figures/Heterogeneous/Uncore1}
    \caption{Effect of uncore power on the energy efficiency of heterogeneous cores, as seen in \cite{heterogeneous-uncore}.}
    \label{fig:Uncore1}
\end{figure}


\todo{WARNING}\textbf{Skipped client workload description}

The analysis considered two uncore conficurations: fixed and scalable.
The first one used the same uncore subsystem for both big and small cores.
The second modelend an uncore where certain components were turned off or powered down when moving to small cores.
Examples are fewer memory channels, controllers, or smaller caches used.  

\begin{figure}[htb]
    \centering
    \includegraphics[width=1.0\textwidth]{Figures/Heterogeneous/Uncore2}
    \caption{Energy savings of using small cores, with core-only savings (C), and with SoC-wide savings (C+UC), with a fixed uncore, and with a scalable uncore, as seen in \cite{heterogeneous-uncore}.}
    \label{fig:Uncore2}
\end{figure}

Figure \cite{fig:Uncore2} shows the energy saved when going from big to small core, with both fixed and scaled uncores.
It is clear that without scaling of the uncores, energy saving is reduced, even lost in some cases.
Figure \cite{fig:Uncore3} shows the relative contrivution of core and uncore energy consumption for all the applications during big core execution, on a fixed uncore configuration.

It is clear that it is important to take uncore power into account for scheduling operations, and design of scalable uncore design is motivated, to obtain large gains from heterogeneous multicores. 

\begin{figure}[htb]
    \centering
    \includegraphics[width=1.0\textwidth]{Figures/Heterogeneous/Uncore3}
    \caption{Core and uncore energy contricution for big cores and fixed uncores, as seen in \cite{heterogeneous-uncore}.}
    \label{fig:Uncore3}
\end{figure}

\section{Bitcoin Hardware}

Tie in with previous heterogeneous stuff laterz.

Due to bitcoin's popularity and the possibility of profits, various specialized hardware has been used
to accelerate the process. Starting with simple programmes running on general-purpose processors,
bitcoin miners soon turned to GPUs in order to improve the performance and power efficiency of the
process. GPUs provide the possibility of running many hashing processes in parallel, in some cases
exceeding 1 GH/s\todo{Add reference to non-specialized hardware comparison on Bitcoin wiki}
\todo{Add reference to later chapter on performance}. FPGA-based bitcoin mining hardware provide
better power efficiency than GPUs due to the possibility of tailoring the hardware design to
bitcoin mining.

However, as bitcoin mining have become more profitable, ASIC-based bitcoin miners have taken over
the market and currently dominates in terms of performance and power efficiency, with performance
exceeding 200 GH/s\todo{reference http://www.spondoolies-tech.com/products/sp35-yukon-power-shipping-from-stock}
per chip\todo{Power?} \cite{bespoke-silicon}.

Suggestion: + those FPGA things?
